services:
  coding-agent:
    build: .
    environment:
      - PROBLEM=${PROBLEM:-Calculate the first 10 Fibonacci numbers}
      - MODEL_PROVIDER=docker-model-runner
      # Use Docker Model Runner's OpenAI-compatible endpoint
      - OPENAI_BASE_URL=http://host.docker.internal/engines/llama.cpp/
      - OPENAI_API_KEY=irrelevant
      - MODEL_NAME=ai/qwen3:8B-Q4_0
      - MCPGATEWAY_URL=http://mcp-gateway:8811
    volumes:
      - ./output:/app/output
      - ./sandbox-output:/app/sandbox-output
    depends_on:
      - mcp-gateway

  mcp-gateway:
    image: docker/mcp-gateway:latest
    ports:
      - "8811:8811"
    use_api_socket: true
    command:
      - --secrets=/run/secrets/mcp_secret
      - --servers=node-code-sandbox
    secrets:
      - mcp_secret

# Docker Model Runner models configuration
models:
  qwen3-small:
    model: ai/qwen3:8B-Q4_0 # 4.44 GB
    context_size: 15000 # 7 GB VRAM
  qwen3-medium:
    model: ai/qwen3:14B-Q6_K # 11.28 GB
    context_size: 15000 # 15 GB VRAM

secrets:
  mcp_secret:
    file: ./.mcp.env
